{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34b68367",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060ccfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b6eef",
   "metadata": {},
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0903edcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(529918, 79)\n",
      "(445909, 79)\n",
      "(692703, 79)\n",
      "(170366, 79)\n",
      "(288602, 79)\n",
      "(191033, 79)\n",
      "(286467, 79)\n",
      "(225745, 79)\n"
     ]
    }
   ],
   "source": [
    "Monday_df = pd.read_csv('archive_2/Monday_WorkingHours.csv')\n",
    "Monday_df = pd.DataFrame(Monday_df)\n",
    "print(Monday_df.shape) \n",
    "Monday_df.columns = Monday_df.columns.str.strip() #Remove extra spaces from column names\n",
    "\n",
    "Tuesday_BruteForce = pd.read_csv('archive_2/Tuesday_BruteForce.csv')\n",
    "Tuesday_BruteForce = pd.DataFrame(Tuesday_BruteForce)\n",
    "print(Tuesday_BruteForce.shape)\n",
    "Tuesday_BruteForce.columns = Tuesday_BruteForce.columns.str.strip()\n",
    "\n",
    "Wednesday_DOS = pd.read_csv('archive_2/Wednesday_DOS_DDOS.csv')\n",
    "Wednesday_DOS = pd.DataFrame(Wednesday_DOS)\n",
    "print(Wednesday_DOS.shape)\n",
    "Wednesday_DOS.columns = Wednesday_DOS.columns.str.strip() \n",
    "\n",
    "Thursday_WebAttack = pd.read_csv('archive_2/Thursday_Morning_WebAttacks.csv')\n",
    "Thursday_WebAttack = pd.DataFrame(Thursday_WebAttack)\n",
    "print(Thursday_WebAttack.shape)\n",
    "Thursday_WebAttack.columns = Thursday_WebAttack.columns.str.strip()\n",
    "\n",
    "Thursday_Infiltration = pd.read_csv('archive_2/Thursday_Afternoon_Infiltration.csv')\n",
    "Thursday_Infiltration = pd.DataFrame(Thursday_Infiltration)\n",
    "print(Thursday_Infiltration.shape)\n",
    "Thursday_Infiltration.columns = Thursday_Infiltration.columns.str.strip()\n",
    "\n",
    "Friday_Botnet = pd.read_csv('archive_2/Friday_Morning_Botnet.csv')\n",
    "Friday_Botnet = pd.DataFrame(Friday_Botnet)\n",
    "print(Friday_Botnet.shape)\n",
    "Friday_Botnet.columns = Friday_Botnet.columns.str.strip()\n",
    "\n",
    "Friday_Portscan = pd.read_csv('archive_2/Friday_Afternoon_PortScan.csv')\n",
    "Friday_Portscan = pd.DataFrame(Friday_Portscan)\n",
    "print(Friday_Portscan.shape)\n",
    "Friday_Portscan.columns = Friday_Portscan.columns.str.strip()\n",
    "\n",
    "Friday_DDOS = pd.read_csv('archive_2/Friday_Afternoon_DDos.csv')\n",
    "Friday_DDOS = pd.DataFrame(Friday_DDOS)\n",
    "print(Friday_DDOS.shape)\n",
    "Friday_DDOS.columns = Friday_DDOS.columns.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45571ce8",
   "metadata": {},
   "source": [
    "#### Explore columns to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "877d18e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'common_duplicate': [('Bwd PSH Flags', 'Bwd Avg Bulk Rate'), ('Bwd PSH Flags', 'Bwd Avg Bytes/Bulk'), ('Bwd PSH Flags', 'Bwd Avg Packets/Bulk'), ('Bwd PSH Flags', 'Bwd URG Flags'), ('Bwd PSH Flags', 'Fwd Avg Bulk Rate'), ('Bwd PSH Flags', 'Fwd Avg Bytes/Bulk'), ('Bwd PSH Flags', 'Fwd Avg Packets/Bulk'), ('Fwd Header Length', 'Fwd Header Length.1'), ('Fwd Header Length.1', 'Fwd Header Length'), ('Fwd PSH Flags', 'SYN Flag Count'), ('SYN Flag Count', 'Fwd PSH Flags'), ('Subflow Bwd Packets', 'Total Backward Packets'), ('Subflow Fwd Packets', 'Total Fwd Packets'), ('Total Backward Packets', 'Subflow Bwd Packets'), ('Total Fwd Packets', 'Subflow Fwd Packets')], 'common_constant': ['Bwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd PSH Flags', 'Bwd URG Flags', 'Fwd Avg Bulk Rate', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk'], 'common_missing': ['Flow Bytes/s']}\n"
     ]
    }
   ],
   "source": [
    "def analyzeFeatures(df):\n",
    "    results = {}\n",
    "    # Duplicate columns\n",
    "    checked = []\n",
    "    duplicate_cols = []\n",
    "    for col1 in df.columns:\n",
    "        for col2 in df.columns:\n",
    "            if col1 != col2 and col2 not in checked:\n",
    "                if df[col1].equals(df[col2]):\n",
    "                    duplicate_cols.append((col1,col2))\n",
    "                    checked.append(col2)\n",
    "    results['duplicates'] = duplicate_cols\n",
    "\n",
    "    #Not unique columns\n",
    "    constant_cols = [col for col in df.columns if df[col].nunique() == 1]\n",
    "    results['constant_cols'] = constant_cols\n",
    "\n",
    "    #Missing value columns\n",
    "    missing = df.isna().mean().sort_values(ascending=False)\n",
    "    results['missing'] = missing[missing > 0].to_dict()\n",
    "\n",
    "    return results\n",
    "\n",
    "Mon_features = analyzeFeatures(Monday_df)\n",
    "BruteForce_features = analyzeFeatures(Tuesday_BruteForce)\n",
    "DOS_features = analyzeFeatures(Wednesday_DOS)\n",
    "WebAttack_features = analyzeFeatures(Thursday_WebAttack)\n",
    "Infiltration_features = analyzeFeatures(Thursday_Infiltration)\n",
    "Botnet_features = analyzeFeatures(Friday_Botnet)\n",
    "Portscan_features = analyzeFeatures(Friday_Portscan)\n",
    "DDOS_features = analyzeFeatures(Friday_DDOS)\n",
    "\n",
    "dataset_features = [Mon_features, BruteForce_features, DOS_features, WebAttack_features, Infiltration_features, Botnet_features, Portscan_features, DDOS_features]\n",
    "\n",
    "def feature_summary(dataset_features):\n",
    "    duplicate_lists = [set(map(tuple, d['duplicates'])) for d in dataset_features]\n",
    "    constant_lists = [set(d['constant_cols']) for d in dataset_features]\n",
    "    missing_lists = [set(d['missing'].keys()) for d in dataset_features]\n",
    "\n",
    "    common_duplicates = set.intersection(*duplicate_lists) if duplicate_lists else set()\n",
    "    common_constants = set.intersection(*constant_lists) if constant_lists else set()\n",
    "    common_missing = set.intersection(*missing_lists) if missing_lists else set()\n",
    "\n",
    "    return {\n",
    "        'common_duplicate': sorted(list(common_duplicates)),\n",
    "        'common_constant': sorted(list(common_constants)),\n",
    "        'common_missing': sorted(list(common_missing))\n",
    "    }\n",
    "\n",
    "summary = feature_summary(dataset_features)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f958b9e",
   "metadata": {},
   "source": [
    "#### Drop columns and create y dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9ff69ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyLabelDropColumns(df):\n",
    "    yDF = df[['Label']].copy()\n",
    "    newDF = df.drop(['Destination Port', 'Label', 'Bwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd PSH Flags', 'Bwd URG Flags', 'Fwd Avg Bulk Rate', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Header Length.1', 'Fwd PSH Flags', 'Subflow Bwd Packets','Subflow Fwd Packets'], axis=1)\n",
    "    return yDF, newDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "63c5ee8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(529918, 65)\n",
      "(445909, 65)\n",
      "(692703, 65)\n",
      "(170366, 65)\n",
      "(288602, 65)\n",
      "(191033, 65)\n",
      "(286467, 65)\n",
      "(225745, 65)\n"
     ]
    }
   ],
   "source": [
    "#Monday\n",
    "Mon_df_y, Mon_drop_df = copyLabelDropColumns(Monday_df)\n",
    "#print(Mon_df_y[:5])\n",
    "print(Mon_drop_df.shape)\n",
    "\n",
    "#Tuesday Brute Force\n",
    "BruteForce_df_y, BruteForce_drop_df = copyLabelDropColumns(Tuesday_BruteForce)\n",
    "#print(BruteForce_df_y[:5])\n",
    "print(BruteForce_drop_df.shape)\n",
    "\n",
    "#Wednesday DOS\n",
    "DOS_df_y, DOS_drop_df = copyLabelDropColumns(Wednesday_DOS)\n",
    "#print(DOS_df_y[:5])\n",
    "print(DOS_drop_df.shape)\n",
    "\n",
    "#Thursday Web Attack\n",
    "WebAttack_df_y, WebAttack_drop_df = copyLabelDropColumns(Thursday_WebAttack)\n",
    "#print(WebAttack_df_y[:5])\n",
    "print(WebAttack_drop_df.shape)\n",
    "\n",
    "#Thursday Infiltration\n",
    "Infiltration_df_y, Infiltration_drop_df = copyLabelDropColumns(Thursday_Infiltration)\n",
    "#print(Infiltration_df_y[:5])\n",
    "print(Infiltration_drop_df.shape)\n",
    "\n",
    "#Friday Botnet\n",
    "Botnet_df_y, Botnet_drop_df = copyLabelDropColumns(Friday_Botnet)\n",
    "#print(Botnet_df_y[:5])\n",
    "print(Botnet_drop_df.shape)\n",
    "\n",
    "#Friday Portscan\n",
    "Portscan_df_y, Portscan_drop_df = copyLabelDropColumns(Friday_Portscan)\n",
    "#print(Portscan_df_y[:5])\n",
    "print(Portscan_drop_df.shape)\n",
    "\n",
    "#Friday DDOS\n",
    "DDOS_df_y, DDOS_drop_df = copyLabelDropColumns(Friday_DDOS)\n",
    "#print(DDOS_df_y[:5])\n",
    "print(DDOS_drop_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa479b5",
   "metadata": {},
   "source": [
    "#### What columns are left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "92a8b4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets',\n",
      "       'Total Length of Fwd Packets', 'Total Length of Bwd Packets',\n",
      "       'Fwd Packet Length Max', 'Fwd Packet Length Min',\n",
      "       'Fwd Packet Length Mean', 'Fwd Packet Length Std',\n",
      "       'Bwd Packet Length Max', 'Bwd Packet Length Min',\n",
      "       'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s',\n",
      "       'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max',\n",
      "       'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std',\n",
      "       'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean',\n",
      "       'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd URG Flags',\n",
      "       'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s',\n",
      "       'Bwd Packets/s', 'Min Packet Length', 'Max Packet Length',\n",
      "       'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance',\n",
      "       'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count',\n",
      "       'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count',\n",
      "       'Down/Up Ratio', 'Average Packet Size', 'Avg Fwd Segment Size',\n",
      "       'Avg Bwd Segment Size', 'Subflow Fwd Bytes', 'Subflow Bwd Bytes',\n",
      "       'Init_Win_bytes_forward', 'Init_Win_bytes_backward', 'act_data_pkt_fwd',\n",
      "       'min_seg_size_forward', 'Active Mean', 'Active Std', 'Active Max',\n",
      "       'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(DDOS_drop_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d6fc78",
   "metadata": {},
   "source": [
    "#### Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0fc0d65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeLabels(df):\n",
    "    df['Label_encoding'] = df['Label'].apply(lambda x: 0 if x == 'BENIGN' else 1)\n",
    "    df = df.drop(['Label'], axis=1)\n",
    "    return df\n",
    "\n",
    "Mon_df_y = encodeLabels(Mon_df_y)\n",
    "#Make into series\n",
    "Mon_df_y = Mon_df_y['Label_encoding'] \n",
    "#print(Mon_df_y[:5])\n",
    "\n",
    "BruteForce_df_y = encodeLabels(BruteForce_df_y)\n",
    "#Make into series\n",
    "BruteForce_df_y = BruteForce_df_y['Label_encoding'] \n",
    "#print(BruteForce_df_y[:5])\n",
    "\n",
    "DOS_df_y = encodeLabels(DOS_df_y)\n",
    "#Make into series\n",
    "DOS_df_y = DOS_df_y['Label_encoding'] \n",
    "#print(DOS_df_y[:5])\n",
    "\n",
    "WebAttack_df_y = encodeLabels(WebAttack_df_y)\n",
    "#Make into series\n",
    "WebAttack_df_y = WebAttack_df_y['Label_encoding']\n",
    "#print(WebAttack_df_y[:5])\n",
    "\n",
    "Infiltration_df_y = encodeLabels(Infiltration_df_y)\n",
    "#Make into series\n",
    "Infiltration_df_y = Infiltration_df_y['Label_encoding']\n",
    "#print(Infiltration_df_y[:5])\n",
    "\n",
    "Botnet_df_y = encodeLabels(Botnet_df_y)\n",
    "#Make into series\n",
    "Botnet_df_y = Botnet_df_y['Label_encoding']\n",
    "#print(Botnet_df_y[:5])\n",
    "\n",
    "Portscan_df_y = encodeLabels(Portscan_df_y)\n",
    "#Make into series\n",
    "Portscan_df_y = Portscan_df_y['Label_encoding']\n",
    "#print(Portscan_df_y[:5])\n",
    "\n",
    "DDOS_df_y = encodeLabels(DDOS_df_y)\n",
    "#Make into series\n",
    "DDOS_df_y = DDOS_df_y['Label_encoding']\n",
    "#print(DDOS_df_y[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4ba544",
   "metadata": {},
   "source": [
    "#### Check that correct labels are maintained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5268e0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Monday: ', '\\n', Mon_df_y['Label_encoding'].value_counts())\n",
    "#print('BruteForce:', '\\n',  BruteForce_df_y['Label_encoding'].value_counts())\n",
    "#print('DOS: ', '\\n', DOS_df_y['Label_encoding'].value_counts())\n",
    "#print('WebAttack: ', '\\n', WebAttack_df_y['Label_encoding'].value_counts())\n",
    "#print('Infiltration: ', '\\n', Infiltration_df_y['Label_encoding'].value_counts())\n",
    "#print('Botnet: ', '\\n', Botnet_df_y['Label_encoding'].value_counts())\n",
    "#print('Portscan: ', '\\n', Portscan_df_y['Label_encoding'].value_counts())\n",
    "#print('DDOS: ', '\\n', DDOS_df_y['Label_encoding'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859f57ed",
   "metadata": {},
   "source": [
    "#### Train test split all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3b9a4d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monday train, test split\n",
    "X_Mon_train, X_Mon_test, Y_Mon_train, Y_Mon_test = train_test_split(\n",
    "    Mon_drop_df, Mon_df_y, \n",
    "    test_size=.2, \n",
    "    stratify=Mon_df_y, \n",
    "    random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9ceeddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BruteForce train, test split\n",
    "X_BruteForce_train, X_BruteForce_test, Y_BruteForce_train, Y_BruteForce_test = train_test_split(\n",
    "    BruteForce_drop_df, BruteForce_df_y, \n",
    "    test_size=.2, \n",
    "    stratify=BruteForce_df_y, \n",
    "    random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5bef1285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOS train, test split\n",
    "X_DOS_train, X_DOS_test, Y_DOS_train, Y_DOS_test = train_test_split(\n",
    "    DOS_drop_df, DOS_df_y, \n",
    "    test_size=.2, \n",
    "    stratify=DOS_df_y, \n",
    "    random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "86fc48d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WebAttack train, test split\n",
    "X_WebAttack_train, X_WebAttack_test, Y_WebAttack_train, Y_WebAttack_test = train_test_split(\n",
    "    WebAttack_drop_df, WebAttack_df_y, \n",
    "    test_size=.2, \n",
    "    stratify=WebAttack_df_y, \n",
    "    random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d4872d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Infiltration train, test split\n",
    "X_Infiltration_train, X_Infiltration_test, Y_Infiltration_train, Y_Infiltration_test = train_test_split(\n",
    "    Infiltration_drop_df, Infiltration_df_y, \n",
    "    test_size=.2, \n",
    "    stratify=Infiltration_df_y, \n",
    "    random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f9edf6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Botnet train, test split\n",
    "X_Botnet_train, X_Botnet_test, Y_Botnet_train, Y_Botnet_test = train_test_split(\n",
    "    Botnet_drop_df, Botnet_df_y, \n",
    "    test_size=.2, \n",
    "    stratify=Botnet_df_y, \n",
    "    random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "26f12d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Portscan train, test split\n",
    "X_Portscan_train, X_Portscan_test, Y_Portscan_train, Y_Portscan_test = train_test_split(\n",
    "    Portscan_drop_df, Portscan_df_y, \n",
    "    test_size=.2, \n",
    "    stratify=Portscan_df_y, \n",
    "    random_state=28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "38f0a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Portscan train, test split\n",
    "X_DDOS_train, X_DDOS_test, Y_DDOS_train, Y_DDOS_test = train_test_split(\n",
    "    DDOS_drop_df, DDOS_df_y, \n",
    "    test_size=.2, \n",
    "    stratify=DDOS_df_y, \n",
    "    random_state=28)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a648745",
   "metadata": {},
   "source": [
    "#### Add Monday to all attack days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cf112ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addMonday(x_train, x_test, y_train, y_test):\n",
    "    concat_x_train = pd.concat([X_Mon_train, x_train], ignore_index=True)\n",
    "    concat_x_test = pd.concat([X_Mon_test, x_test], ignore_index=True)\n",
    "    concat_y_train = pd.concat([Y_Mon_train, y_train], ignore_index=True)\n",
    "    concat_y_test = pd.concat([Y_Mon_test, y_test], ignore_index=True)\n",
    "    return concat_x_train, concat_x_test, concat_y_train, concat_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "91fa2371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat BruteForce\n",
    "BruteForceMon_x_train, BruteForceMon_x_test, BruteForceMon_y_train, BruteForceMon_y_test = addMonday(X_BruteForce_train, X_BruteForce_test, Y_BruteForce_train, Y_BruteForce_test)\n",
    "\n",
    "#Concat DOS\n",
    "DOSMon_x_train, DOSMon_x_test, DOSMon_y_train, DOSMon_y_test = addMonday(X_DOS_train, X_DOS_test, Y_DOS_train, Y_DOS_test)\n",
    "\n",
    "#Concat WebAttack\n",
    "WebAttackMon_x_train, WebAttackMon_x_test, WebAttackMon_y_train, WebAttackMon_y_test = addMonday(X_WebAttack_train, X_WebAttack_test, Y_WebAttack_train, Y_WebAttack_test)\n",
    "\n",
    "#Concat Infiltration\n",
    "InfiltrationMon_x_train, InfiltrationMon_x_test, InfiltrationMon_y_train, InfiltrationMon_y_test = addMonday(X_Infiltration_train, X_Infiltration_test, Y_Infiltration_train, Y_Infiltration_test)\n",
    "\n",
    "#Concat Botnet\n",
    "BotnetMon_x_train, BotnetMon_x_test, BotnetMon_y_train, BotnetMon_y_test = addMonday(X_Botnet_train, X_Botnet_test, Y_Botnet_train, Y_Botnet_test)\n",
    "\n",
    "#Concat Portscan\n",
    "PortscanMon_x_train, PortscanMon_x_test, PortscanMon_y_train, PortscanMon_y_test = addMonday(X_Portscan_train, X_Portscan_test, Y_Portscan_train, Y_Portscan_test)\n",
    "\n",
    "#Concat DDOS\n",
    "DDOSMon_x_train, DDOSMon_x_test, DDOSMon_y_train, DDOSMon_y_test = addMonday(X_DDOS_train, X_DDOS_test, Y_DDOS_train, Y_DDOS_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee109f8f",
   "metadata": {},
   "source": [
    "#### Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b63f6ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleFeatures(train, test):\n",
    "    # Replace infinities with NaN\n",
    "    train = train.replace([np.inf, -np.inf], np.nan)\n",
    "    test  = test.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # Handle NaNs by filling with median of column\n",
    "    train_medians = train.median()\n",
    "    train = train.fillna(train_medians)\n",
    "    test  = test.fillna(train_medians)\n",
    "\n",
    "    #Declare scaler, fit on training\n",
    "    scaler = MinMaxScaler().fit(train)\n",
    "\n",
    "    #Transform train, test\n",
    "    train_scaled = pd.DataFrame(scaler.transform(train), columns=train.columns)\n",
    "    test_scaled  = pd.DataFrame(scaler.transform(test), columns=test.columns)\n",
    "\n",
    "    return train_scaled, test_scaled\n",
    "\n",
    "#Scale BruteForce\n",
    "BruteForceMon_x_train, BruteForceMon_x_test = scaleFeatures(BruteForceMon_x_train, BruteForceMon_x_test)\n",
    "#Scale DOS\n",
    "DOSMon_x_train, DOSMon_x_test = scaleFeatures(DOSMon_x_train, DOSMon_x_test)\n",
    "#Scale WebAttack\n",
    "WebAttackMon_x_train, WebAttackMon_x_test = scaleFeatures(WebAttackMon_x_train, WebAttackMon_x_test)\n",
    "#Scale Infiltration\n",
    "InfiltrationMon_x_train, InfiltrationMon_x_test = scaleFeatures(InfiltrationMon_x_train, InfiltrationMon_x_test)\n",
    "#Scale Botnet\n",
    "BotnetMon_x_train, BotnetMon_x_test = scaleFeatures(BotnetMon_x_train, BotnetMon_x_test)\n",
    "#Scale Portscan\n",
    "PortscanMon_x_train, PortscanMon_x_test = scaleFeatures(PortscanMon_x_train, PortscanMon_x_test)\n",
    "#Scale DDOS\n",
    "DDOSMon_x_train, DDOSMon_x_test = scaleFeatures(DDOSMon_x_train, DDOSMon_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65c7e18",
   "metadata": {},
   "source": [
    "#### The Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "07ab6304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "logistic = LogisticRegression(max_iter=2000)\n",
    "\n",
    "scoring = {'AUC': 'roc_auc', 'Accuracy': 'accuracy', 'Average Precision': 'average_precision', 'F1': 'f1'}\n",
    "\n",
    "param_grid_logistic = [\n",
    "    # L2 penalties\n",
    "    {\n",
    "        'penalty': ['l2'],\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'solver': ['lbfgs', 'newton-cg', 'saga']\n",
    "    },\n",
    "    \n",
    "    # L1 penalties\n",
    "    {\n",
    "        'penalty': ['l1'],\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    },\n",
    "    \n",
    "    # No penalty\n",
    "    {\n",
    "        'penalty': ['None'],\n",
    "        'solver': ['lbfgs', 'newton-cg', 'saga']\n",
    "    },\n",
    "    \n",
    "    # ElasticNet\n",
    "    {\n",
    "        'penalty': ['elasticnet'],\n",
    "        'C': [0.1, 1],\n",
    "        'solver': ['saga'],\n",
    "        'l1_ratio': [0.1, 0.5, 0.9]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Setting refit='AUC', refits an estimator on the whole dataset with the\n",
    "# parameter setting that has the best cross-validated AUC score.\n",
    "# That estimator is made available at ``gs.best_estimator_`` along with\n",
    "# parameters like ``gs.best_score_``, ``gs.best_params_`` and\n",
    "# ``gs.best_index_``\n",
    "grid_search_logistic = GridSearchCV(\n",
    "    logistic, \n",
    "    param_grid=param_grid_logistic,\n",
    "    refit='AUC', #refits estimator on the whole dataset with parameter setting\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring=scoring\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cf6de526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto'],\n",
    "    'leaf_size': [30, 40]\n",
    "}\n",
    "grid_search_knn = GridSearchCV(\n",
    "    knn,\n",
    "    param_grid=param_grid_knn,\n",
    "    refit='AUC',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring=scoring\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "274217c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classifier\n",
    "random = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [200, 500],       \n",
    "    'max_depth': [None, 15, 30],      \n",
    "    'min_samples_split': [2, 5],      \n",
    "    'min_samples_leaf': [1, 2],       \n",
    "    'max_features': ['sqrt'] \n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    random,\n",
    "    param_grid=param_grid_rf,\n",
    "    refit='AUC',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring=scoring   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fe1e0234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP Classifier\n",
    "mlpclassifier = MLPClassifier(max_iter=2000)\n",
    "\n",
    "param_grid_mlp = {\n",
    "   'hidden_layer_sizes': [(64,), (128,), (128, 64)],\n",
    "    'activation': ['relu'],     \n",
    "    'solver': ['adam'],         \n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['adaptive']\n",
    "}\n",
    "\n",
    "grid_search_mlp = GridSearchCV(\n",
    "   mlpclassifier,\n",
    "   param_grid=param_grid_mlp,\n",
    "   refit='AUC',\n",
    "   cv=5,\n",
    "   n_jobs=-1,\n",
    "   scoring=scoring\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2319d417",
   "metadata": {},
   "source": [
    "#### Brute Force Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4e10d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 145.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'none' (deprecated), 'elasticnet', 'l2'} or None. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89521135 0.89520852 0.895209   0.93465508 0.93465156 0.93465156\n",
      " 0.96300997 0.96300786 0.96300693 0.97634795 0.97634771 0.976328\n",
      " 0.39280387 0.701528   0.94693198 0.94574984 0.97876695 0.97824792\n",
      " 0.99253697 0.98761803        nan        nan        nan 0.93434893\n",
      " 0.93485282 0.93936981 0.96354849 0.96639693 0.97155227]\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.9858325  0.9858325  0.9858325  0.9858325  0.9858325  0.9858325\n",
      " 0.98578127 0.98578127 0.98578127 0.98557631 0.98557631 0.9855507\n",
      " 0.9858325  0.9858325  0.9858325  0.9858325  0.98649857 0.98567877\n",
      " 0.99490175 0.99295469        nan        nan        nan 0.9858325\n",
      " 0.9858325  0.9858325  0.98578127 0.98578127 0.98570441]\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.07859735 0.07859589 0.07859519 0.16991864 0.17007914 0.17009281\n",
      " 0.25547321 0.2554474  0.25545734 0.49998235 0.5000047  0.498205\n",
      " 0.01657271 0.0281726  0.17095598 0.16755146 0.48807474 0.47781874\n",
      " 0.8049977  0.73896618        nan        nan        nan 0.16760984\n",
      " 0.17373302 0.1636512  0.2595308  0.29167517 0.37064407]\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.01626984 0.01626984 0.01317143\n",
      " 0.         0.         0.         0.         0.19912892 0.12373672\n",
      " 0.79720587 0.67831404        nan        nan        nan 0.\n",
      " 0.         0.         0.         0.         0.        ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brute Force\n",
      "Logistic Regression\n",
      "Best parameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best cross-val score: 99.25%\n",
      "\n",
      "\n",
      "KNN\n",
      "Best parameters: {'algorithm': 'auto', 'leaf_size': 30, 'n_neighbors': 7, 'weights': 'distance'}\n",
      "Best score: 99.35%\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Best parameters: {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best score : 99.99%\n",
      "\n",
      "\n",
      "Multi-Layer Perceptron\n",
      "Best parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "Best score: 99.57%\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter training subset split\n",
    "BruteForce_x_train_subset, _, BruteForce_y_train_subset, _ = train_test_split(\n",
    "    BruteForceMon_x_train, BruteForceMon_y_train,\n",
    "    train_size=0.05,            \n",
    "    stratify=BruteForceMon_y_train,          \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "#Logistic Regression\n",
    "grid_search_logistic.fit(BruteForce_x_train_subset, BruteForce_y_train_subset)\n",
    "BF_logistic_bestestimator = grid_search_logistic.best_estimator_\n",
    "BF_logistic_bestparams = grid_search_logistic.best_params_\n",
    "BF_logistic_bestscore = grid_search_logistic.best_score_\n",
    "print('Brute Force')\n",
    "print('Logistic Regression')\n",
    "print(\"Best parameters:\", BF_logistic_bestparams)\n",
    "print(\"Best cross-val score: {:.2f}%\".format(BF_logistic_bestscore * 100))\n",
    "print('\\n')\n",
    "\n",
    "#KNN\n",
    "grid_search_knn.fit(BruteForce_x_train_subset, BruteForce_y_train_subset)\n",
    "BF_knn_bestestimator = grid_search_knn.best_estimator_\n",
    "BF_knn_bestparams = grid_search_knn.best_params_\n",
    "BF_knn_bestscore = grid_search_knn.best_score_\n",
    "print('KNN')\n",
    "print(\"Best parameters:\", BF_knn_bestparams)\n",
    "print(\"Best score: {:.2f}%\".format(BF_knn_bestscore * 100))\n",
    "print('\\n')\n",
    "\n",
    "#Random Forest Classifier\n",
    "grid_search_rf.fit(BruteForce_x_train_subset, BruteForce_y_train_subset)\n",
    "BF_rf_bestestimator = grid_search_rf.best_estimator_\n",
    "BF_rf_bestparams = grid_search_rf.best_params_\n",
    "BF_rf_bestscore = grid_search_rf.best_score_\n",
    "print('Random Forest')\n",
    "print(\"Best parameters:\", BF_rf_bestparams)\n",
    "print(\"Best score : {:.2f}%\".format(BF_rf_bestscore * 100))\n",
    "print('\\n')\n",
    "\n",
    "#MLP Classifier\n",
    "grid_search_mlp.fit(BruteForce_x_train_subset, BruteForce_y_train_subset)\n",
    "BF_mlp_bestestimator = grid_search_mlp.best_estimator_\n",
    "BF_mlp_bestparams = grid_search_mlp.best_params_\n",
    "BF_mlp_bestscore = grid_search_mlp.best_score_\n",
    "print('Multi-Layer Perceptron')\n",
    "print(\"Best parameters:\", BF_mlp_bestparams)\n",
    "print(\"Best score: {:.2f}%\".format(BF_mlp_bestscore * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dc3abb",
   "metadata": {},
   "source": [
    "#### DOS Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bab646a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 145.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2', 'none' (deprecated)} or None. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.9629397  0.96294008 0.96293962 0.9715884  0.97158843 0.97158843\n",
      " 0.97852539 0.97852168 0.97852241 0.98293697 0.98293571 0.98291008\n",
      " 0.95566178 0.9548714  0.97582085 0.97582822 0.9852526  0.98516114\n",
      " 0.98868444 0.98769022        nan        nan        nan 0.97168537\n",
      " 0.9724676  0.97472005 0.97867207 0.9795163  0.98190699]\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.91626453 0.91626453 0.91626453 0.9302307  0.9302307  0.9302307\n",
      " 0.93147802 0.93147802 0.93147802 0.94628251 0.94626206 0.94613937\n",
      " 0.91769589 0.91747096 0.93147804 0.93149849 0.94957467 0.94926795\n",
      " 0.96123015 0.95947158        nan        nan        nan 0.9302307\n",
      " 0.93043518 0.93119177 0.93162116 0.93417719 0.94564861]\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.911774   0.91177487 0.91177325 0.92821293 0.92821365 0.92821364\n",
      " 0.94367046 0.94366195 0.94366329 0.95441591 0.95440589 0.95433295\n",
      " 0.90488833 0.90495512 0.93611651 0.93609025 0.95936637 0.95924633\n",
      " 0.96775355 0.96641952        nan        nan        nan 0.92837164\n",
      " 0.92972054 0.93446635 0.94404706 0.94619842 0.95153386]\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.755706   0.755706   0.755706   0.80432867 0.80432867 0.80432867\n",
      " 0.81037854 0.81037854 0.81037854 0.85965538 0.85960916 0.85931931\n",
      " 0.76113457 0.76038687 0.80930012 0.8093876  0.86783883 0.86712931\n",
      " 0.90086301 0.89632624        nan        nan        nan 0.80435121\n",
      " 0.80494441 0.80751894 0.81087259 0.81935968 0.85771186]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOS\n",
      "Logistic Regression\n",
      "Best parameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best cross-val score: 98.87%\n",
      "\n",
      "\n",
      "KNN\n",
      "Best parameters: {'algorithm': 'auto', 'leaf_size': 30, 'n_neighbors': 9, 'weights': 'distance'}\n",
      "Best score: 99.89%\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Best parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best score : 100.00%\n",
      "\n",
      "\n",
      "Multi-Layer Perceptron\n",
      "Best parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "Best score: 99.81%\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter training subset split\n",
    "DOS_x_train_subset, _, DOS_y_train_subset, _ = train_test_split(\n",
    "    DOSMon_x_train, DOSMon_y_train,\n",
    "    train_size=0.05,            \n",
    "    stratify=DOSMon_y_train,          \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "#Logistic Regression\n",
    "grid_search_logistic.fit(DOS_x_train_subset, DOS_y_train_subset)\n",
    "DOS_logistic_bestestimator = grid_search_logistic.best_estimator_\n",
    "DOS_logistic_bestparams = grid_search_logistic.best_params_\n",
    "DOS_logistic_bestscore = grid_search_logistic.best_score_\n",
    "print('DOS')\n",
    "print('Logistic Regression')\n",
    "print(\"Best parameters:\", DOS_logistic_bestparams)\n",
    "print(\"Best cross-val score: {:.2f}%\".format(DOS_logistic_bestscore * 100))\n",
    "print('\\n')\n",
    "\n",
    "#KNN\n",
    "grid_search_knn.fit(DOS_x_train_subset, DOS_y_train_subset)\n",
    "DOS_knn_bestestimator = grid_search_knn.best_estimator_\n",
    "DOS_knn_bestparams = grid_search_knn.best_params_\n",
    "DOS_knn_bestscore = grid_search_knn.best_score_\n",
    "print('KNN')\n",
    "print(\"Best parameters:\", DOS_knn_bestparams)\n",
    "print(\"Best score: {:.2f}%\".format(DOS_knn_bestscore * 100))\n",
    "print('\\n')\n",
    "\n",
    "#Random Forest Classifier\n",
    "grid_search_rf.fit(DOS_x_train_subset, DOS_y_train_subset)\n",
    "DOS_rf_bestestimator = grid_search_rf.best_estimator_\n",
    "DOS_rf_bestparams = grid_search_rf.best_params_\n",
    "DOS_rf_bestscore = grid_search_rf.best_score_\n",
    "print('Random Forest')\n",
    "print(\"Best parameters:\", DOS_rf_bestparams)\n",
    "print(\"Best score : {:.2f}%\".format(DOS_rf_bestscore * 100))\n",
    "print('\\n')\n",
    "\n",
    "#MLP Classifier\n",
    "grid_search_mlp.fit(DOS_x_train_subset, DOS_y_train_subset)\n",
    "DOS_mlp_bestestimator = grid_search_mlp.best_estimator_\n",
    "DOS_mlp_bestparams = grid_search_mlp.best_params_\n",
    "DOS_mlp_bestscore = grid_search_mlp.best_score_\n",
    "print('Multi-Layer Perceptron')\n",
    "print(\"Best parameters:\", DOS_mlp_bestparams)\n",
    "print(\"Best score: {:.2f}%\".format(DOS_mlp_bestscore * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1821b4",
   "metadata": {},
   "source": [
    "#### WebAttack Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc690de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter training subset split\n",
    "WebAttack_x_train_subset, _, WebAttack_y_train_subset, _ = train_test_split(\n",
    "    WebAttackMon_x_train, WebAttackMon_y_train,\n",
    "    train_size=0.05,            \n",
    "    stratify=WebAttackMon_y_train,          \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "#Logistic Regression\n",
    "grid_search_logistic.fit(WebAttack_x_train_subset, WebAttack_y_train_subset)\n",
    "WebAttack_logistic_bestestimator = grid_search_logistic.best_estimator_\n",
    "WebAttack_logistic_bestparams = grid_search_logistic.best_params_\n",
    "WebAttack_logistic_bestscore = grid_search_logistic.best_score_\n",
    "print('WebAttack')\n",
    "print('Logistic Regression')\n",
    "print(\"Best parameters:\", WebAttack_logistic_bestparams)\n",
    "print(\"Best cross-val score: {:.2f}%\".format(WebAttack_logistic_bestscore * 100))\n",
    "print('\\n')\n",
    "\n",
    "#KNN\n",
    "grid_search_knn.fit(WebAttack_x_train_subset, WebAttack_y_train_subset)\n",
    "WebAttack_knn_bestestimator = grid_search_knn.best_estimator_\n",
    "WebAttack_knn_bestparams = grid_search_knn.best_params_\n",
    "WebAttack_knn_bestscore = grid_search_knn.best_score_\n",
    "print('KNN')\n",
    "print(\"Best parameters:\", WebAttack_knn_bestparams)\n",
    "print(\"Best score: {:.2f}%\".format(WebAttack_knn_bestscore * 100))\n",
    "print('\\n')\n",
    "\n",
    "#Random Forest Classifier\n",
    "grid_search_rf.fit(WebAttack_x_train_subset, WebAttack_y_train_subset)\n",
    "WebAttack_rf_bestestimator = grid_search_rf.best_estimator_\n",
    "WebAttack_rf_bestparams = grid_search_rf.best_params_\n",
    "WebAttack_rf_bestscore = grid_search_rf.best_score_\n",
    "print('Random Forest')\n",
    "print(\"Best parameters:\", WebAttack_rf_bestparams)\n",
    "print(\"Best score : {:.2f}%\".format(WebAttack_rf_bestscore * 100))\n",
    "print('\\n')\n",
    "\n",
    "#MLP Classifier\n",
    "grid_search_mlp.fit(WebAttack_x_train_subset, WebAttack_y_train_subset)\n",
    "WebAttack_mlp_bestestimator = grid_search_mlp.best_estimator_\n",
    "WebAttack_mlp_bestparams = grid_search_mlp.best_params_\n",
    "WebAttack_mlp_bestscore = grid_search_mlp.best_score_\n",
    "print('Multi-Layer Perceptron')\n",
    "print(\"Best parameters:\", WebAttack_mlp_bestparams)\n",
    "print(\"Best score: {:.2f}%\".format(WebAttack_mlp_bestscore * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8833cc",
   "metadata": {},
   "source": [
    "#### Infiltration Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2564a75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter training subset split\n",
    "Infiltration_x_train_subset, _, Infiltration_y_train_subset, _ = train_test_split(\n",
    "    InfiltrationMon_x_train, InfiltrationMon_y_train,\n",
    "    train_size=0.05,            \n",
    "    stratify=InfiltrationMon_y_train,          \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "#Logistic Regression\n",
    "grid_search_logistic.fit(Infiltration_x_train_subset, Infiltration_y_train_subset)\n",
    "Infiltration_logistic_bestestimator = grid_search_logistic.best_estimator_\n",
    "Infiltration_logistic_bestparams = grid_search_logistic.best_params_\n",
    "Infiltration_logistic_bestscore = grid_search_logistic.best_score_\n",
    "print('Infiltration')\n",
    "print('Logistic Regression')\n",
    "print(\"Best parameters:\", Infiltration_logistic_bestparams)\n",
    "print(\"Best cross-val score: {:.2f}%\".format(Infiltration_logistic_bestscore * 100))\n",
    "print('\\n')\n",
    "\n",
    "#KNN\n",
    "grid_search_knn.fit(Infiltration_x_train_subset, Infiltration_y_train_subset)\n",
    "Infiltration_knn_bestestimator = grid_search_knn.best_estimator_\n",
    "Infiltration_knn_bestparams = grid_search_knn.best_params_\n",
    "Infiltration_knn_bestscore = grid_search_knn.best_score_\n",
    "print('KNN')\n",
    "print(\"Best parameters:\", Infiltration_knn_bestparams)\n",
    "print(\"Best score: {:.2f}%\".format(Infiltration_knn_bestscore * 100))\n",
    "print('\\n')\n",
    "\n",
    "#Random Forest Classifier\n",
    "grid_search_rf.fit(Infiltration_x_train_subset, Infiltration_y_train_subset)\n",
    "Infiltration_rf_bestestimator = grid_search_rf.best_estimator_\n",
    "Infiltration_rf_bestparams = grid_search_rf.best_params_\n",
    "Infiltration_rf_bestscore = grid_search_rf.best_score_\n",
    "print('Random Forest')\n",
    "print(\"Best parameters:\", Infiltration_rf_bestparams)\n",
    "print(\"Best score : {:.2f}%\".format(Infiltration_rf_bestscore * 100))\n",
    "print('\\n')\n",
    "\n",
    "#MLP Classifier\n",
    "grid_search_mlp.fit(Infiltration_x_train_subset, Infiltration_y_train_subset)\n",
    "Infiltration_mlp_bestestimator = grid_search_mlp.best_estimator_\n",
    "Infiltration_mlp_bestparams = grid_search_mlp.best_params_\n",
    "Infiltration_mlp_bestscore = grid_search_mlp.best_score_\n",
    "print('Multi-Layer Perceptron')\n",
    "print(\"Best parameters:\", Infiltration_mlp_bestparams)\n",
    "print(\"Best score: {:.2f}%\".format(Infiltration_mlp_bestscore * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99bc60e",
   "metadata": {},
   "source": [
    "#### Botnet Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d0ceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter training subset split\n",
    "Botnet_x_train_subset, _, Botnet_y_train_subset, _ = train_test_split(\n",
    "    BotnetMon_x_train, BotnetMon_y_train,\n",
    "    train_size=0.05,            \n",
    "    stratify=BotnetMon_y_train,          \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "#Logistic Regression\n",
    "grid_search_logistic.fit(Botnet_x_train_subset, Botnet_y_train_subset)\n",
    "Botnet_logistic_bestestimator = grid_search_logistic.best_estimator_\n",
    "Botnet_logistic_bestparams = grid_search_logistic.best_params_\n",
    "Botnet_logistic_bestscore = grid_search_logistic.best_score_\n",
    "print('Botnet')\n",
    "print('Logistic Regression')\n",
    "print(\"Best parameters:\", Botnet_logistic_bestparams)\n",
    "print(\"Best cross-val score: {:.2f}%\".format(Botnet_logistic_bestscore * 100))\n",
    "print('\\n')\n",
    "\n",
    "#KNN\n",
    "grid_search_knn.fit(Botnet_x_train_subset, Botnet_y_train_subset)\n",
    "Botnet_knn_bestestimator = grid_search_knn.best_estimator_\n",
    "Botnet_knn_bestparams = grid_search_knn.best_params_\n",
    "Botnet_knn_bestscore = grid_search_knn.best_score_\n",
    "print('KNN')\n",
    "print(\"Best parameters:\", Botnet_knn_bestparams)\n",
    "print(\"Best score: {:.2f}%\".format(Botnet_knn_bestscore * 100))\n",
    "print('\\n')\n",
    "\n",
    "#Random Forest Classifier\n",
    "grid_search_rf.fit(Botnet_x_train_subset, Botnet_y_train_subset)\n",
    "Botnet_rf_bestestimator = grid_search_rf.best_estimator_\n",
    "Botnet_rf_bestparams = grid_search_rf.best_params_\n",
    "Botnet_rf_bestscore = grid_search_rf.best_score_\n",
    "print('Random Forest')\n",
    "print(\"Best parameters:\", Botnet_rf_bestparams)\n",
    "print(\"Best score : {:.2f}%\".format(Botnet_rf_bestscore * 100))\n",
    "print('\\n')\n",
    "\n",
    "#MLP Classifier\n",
    "grid_search_mlp.fit(Botnet_x_train_subset, Botnet_y_train_subset)\n",
    "Botnet_mlp_bestestimator = grid_search_mlp.best_estimator_\n",
    "Botnet_mlp_bestparams = grid_search_mlp.best_params_\n",
    "Botnet_mlp_bestscore = grid_search_mlp.best_score_\n",
    "print('Multi-Layer Perceptron')\n",
    "print(\"Best parameters:\", Botnet_mlp_bestparams)\n",
    "print(\"Best score: {:.2f}%\".format(Botnet_mlp_bestscore * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbf7455",
   "metadata": {},
   "source": [
    "#### Portscan Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5c1e97",
   "metadata": {},
   "source": [
    "#### DDOS Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs135_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
