{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34b68367",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "060ccfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b6eef",
   "metadata": {},
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0903edcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(529918, 79)\n",
      "(445909, 79)\n",
      "(692703, 79)\n",
      "(170366, 79)\n",
      "(288602, 79)\n",
      "(191033, 79)\n",
      "(286467, 79)\n",
      "(225745, 79)\n"
     ]
    }
   ],
   "source": [
    "Monday_df = pd.read_csv('archive_2/Monday_WorkingHours.csv')\n",
    "Monday_df = pd.DataFrame(Monday_df)\n",
    "print(Monday_df.shape) \n",
    "Monday_df.columns = Monday_df.columns.str.strip() #Remove extra spaces from column names\n",
    "\n",
    "Tuesday_BruteForce = pd.read_csv('archive_2/Tuesday_BruteForce.csv')\n",
    "Tuesday_BruteForce = pd.DataFrame(Tuesday_BruteForce)\n",
    "print(Tuesday_BruteForce.shape)\n",
    "Tuesday_BruteForce.columns = Tuesday_BruteForce.columns.str.strip()\n",
    "\n",
    "Wednesday_DOS = pd.read_csv('archive_2/Wednesday_DOS_DDOS.csv')\n",
    "Wednesday_DOS = pd.DataFrame(Wednesday_DOS)\n",
    "print(Wednesday_DOS.shape)\n",
    "Wednesday_DOS.columns = Wednesday_DOS.columns.str.strip() \n",
    "\n",
    "Thursday_WebAttack = pd.read_csv('archive_2/Thursday_Morning_WebAttacks.csv')\n",
    "Thursday_WebAttack = pd.DataFrame(Thursday_WebAttack)\n",
    "print(Thursday_WebAttack.shape)\n",
    "Thursday_WebAttack.columns = Thursday_WebAttack.columns.str.strip()\n",
    "\n",
    "Thursday_Infiltration = pd.read_csv('archive_2/Thursday_Afternoon_Infiltration.csv')\n",
    "Thursday_Infiltration = pd.DataFrame(Thursday_Infiltration)\n",
    "print(Thursday_Infiltration.shape)\n",
    "Thursday_Infiltration.columns = Thursday_Infiltration.columns.str.strip()\n",
    "\n",
    "Friday_Botnet = pd.read_csv('archive_2/Friday_Morning_Botnet.csv')\n",
    "Friday_Botnet = pd.DataFrame(Friday_Botnet)\n",
    "print(Friday_Botnet.shape)\n",
    "Friday_Botnet.columns = Friday_Botnet.columns.str.strip()\n",
    "\n",
    "Friday_Portscan = pd.read_csv('archive_2/Friday_Afternoon_PortScan.csv')\n",
    "Friday_Portscan = pd.DataFrame(Friday_Portscan)\n",
    "print(Friday_Portscan.shape)\n",
    "Friday_Portscan.columns = Friday_Portscan.columns.str.strip()\n",
    "\n",
    "Friday_DDOS = pd.read_csv('archive_2/Friday_Afternoon_DDos.csv')\n",
    "Friday_DDOS = pd.DataFrame(Friday_DDOS)\n",
    "print(Friday_DDOS.shape)\n",
    "Friday_DDOS.columns = Friday_DDOS.columns.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45571ce8",
   "metadata": {},
   "source": [
    "#### Explore columns to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "877d18e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'common_duplicate': [('Bwd PSH Flags', 'Bwd Avg Bulk Rate'), ('Bwd PSH Flags', 'Bwd Avg Bytes/Bulk'), ('Bwd PSH Flags', 'Bwd Avg Packets/Bulk'), ('Bwd PSH Flags', 'Bwd URG Flags'), ('Bwd PSH Flags', 'Fwd Avg Bulk Rate'), ('Bwd PSH Flags', 'Fwd Avg Bytes/Bulk'), ('Bwd PSH Flags', 'Fwd Avg Packets/Bulk'), ('Fwd Header Length', 'Fwd Header Length.1'), ('Fwd Header Length.1', 'Fwd Header Length'), ('Fwd PSH Flags', 'SYN Flag Count'), ('SYN Flag Count', 'Fwd PSH Flags'), ('Subflow Bwd Packets', 'Total Backward Packets'), ('Subflow Fwd Packets', 'Total Fwd Packets'), ('Total Backward Packets', 'Subflow Bwd Packets'), ('Total Fwd Packets', 'Subflow Fwd Packets')], 'common_constant': ['Bwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd PSH Flags', 'Bwd URG Flags', 'Fwd Avg Bulk Rate', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk'], 'common_missing': ['Flow Bytes/s']}\n"
     ]
    }
   ],
   "source": [
    "def analyzeFeatures(df):\n",
    "    results = {}\n",
    "    # Duplicate columns\n",
    "    checked = []\n",
    "    duplicate_cols = []\n",
    "    for col1 in df.columns:\n",
    "        for col2 in df.columns:\n",
    "            if col1 != col2 and col2 not in checked:\n",
    "                if df[col1].equals(df[col2]):\n",
    "                    duplicate_cols.append((col1,col2))\n",
    "                    checked.append(col2)\n",
    "    results['duplicates'] = duplicate_cols\n",
    "\n",
    "    #Not unique columns\n",
    "    constant_cols = [col for col in df.columns if df[col].nunique() == 1]\n",
    "    results['constant_cols'] = constant_cols\n",
    "\n",
    "    #Missing value columns\n",
    "    missing = df.isna().mean().sort_values(ascending=False)\n",
    "    results['missing'] = missing[missing > 0].to_dict()\n",
    "\n",
    "    return results\n",
    "\n",
    "Mon_features = analyzeFeatures(Monday_df)\n",
    "BruteForce_features = analyzeFeatures(Tuesday_BruteForce)\n",
    "DOS_features = analyzeFeatures(Wednesday_DOS)\n",
    "WebAttack_features = analyzeFeatures(Thursday_WebAttack)\n",
    "Infiltration_features = analyzeFeatures(Thursday_Infiltration)\n",
    "Botnet_features = analyzeFeatures(Friday_Botnet)\n",
    "Portscan_features = analyzeFeatures(Friday_Portscan)\n",
    "DDOS_features = analyzeFeatures(Friday_DDOS)\n",
    "\n",
    "dataset_features = [Mon_features, BruteForce_features, DOS_features, WebAttack_features, Infiltration_features, Botnet_features, Portscan_features, DDOS_features]\n",
    "\n",
    "def feature_summary(dataset_features):\n",
    "    duplicate_lists = [set(map(tuple, d['duplicates'])) for d in dataset_features]\n",
    "    constant_lists = [set(d['constant_cols']) for d in dataset_features]\n",
    "    missing_lists = [set(d['missing'].keys()) for d in dataset_features]\n",
    "\n",
    "    common_duplicates = set.intersection(*duplicate_lists) if duplicate_lists else set()\n",
    "    common_constants = set.intersection(*constant_lists) if constant_lists else set()\n",
    "    common_missing = set.intersection(*missing_lists) if missing_lists else set()\n",
    "\n",
    "    return {\n",
    "        'common_duplicate': sorted(list(common_duplicates)),\n",
    "        'common_constant': sorted(list(common_constants)),\n",
    "        'common_missing': sorted(list(common_missing))\n",
    "    }\n",
    "\n",
    "summary = feature_summary(dataset_features)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f958b9e",
   "metadata": {},
   "source": [
    "#### Drop columns and create y dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ff69ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyLabelDropColumns(df):\n",
    "    yDF = df[['Label']].copy()\n",
    "    newDF = df.drop(['Destination Port', 'Label', 'Bwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd PSH Flags', 'Bwd URG Flags', 'Fwd Avg Bulk Rate', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Header Length.1', 'Fwd PSH Flags', 'Subflow Bwd Packets','Subflow Fwd Packets'], axis=1)\n",
    "    return yDF, newDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63c5ee8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(529918, 65)\n",
      "(445909, 65)\n",
      "(692703, 65)\n",
      "(170366, 65)\n",
      "(288602, 65)\n",
      "(191033, 65)\n",
      "(286467, 65)\n",
      "(225745, 65)\n"
     ]
    }
   ],
   "source": [
    "#Monday\n",
    "Mon_df_y, Mon_drop_df = copyLabelDropColumns(Monday_df)\n",
    "#print(Mon_df_y[:5])\n",
    "print(Mon_drop_df.shape)\n",
    "\n",
    "#Tuesday Brute Force\n",
    "BruteForce_df_y, BruteForce_drop_df = copyLabelDropColumns(Tuesday_BruteForce)\n",
    "#print(BruteForce_df_y[:5])\n",
    "print(BruteForce_drop_df.shape)\n",
    "\n",
    "#Wednesday DOS\n",
    "DOS_df_y, DOS_drop_df = copyLabelDropColumns(Wednesday_DOS)\n",
    "#print(DOS_df_y[:5])\n",
    "print(DOS_drop_df.shape)\n",
    "\n",
    "#Thursday Web Attack\n",
    "WebAttack_df_y, WebAttack_drop_df = copyLabelDropColumns(Thursday_WebAttack)\n",
    "#print(WebAttack_df_y[:5])\n",
    "print(WebAttack_drop_df.shape)\n",
    "\n",
    "#Thursday Infiltration\n",
    "Infiltration_df_y, Infiltration_drop_df = copyLabelDropColumns(Thursday_Infiltration)\n",
    "#print(Infiltration_df_y[:5])\n",
    "print(Infiltration_drop_df.shape)\n",
    "\n",
    "#Friday Botnet\n",
    "Botnet_df_y, Botnet_drop_df = copyLabelDropColumns(Friday_Botnet)\n",
    "#print(Botnet_df_y[:5])\n",
    "print(Botnet_drop_df.shape)\n",
    "\n",
    "#Friday Portscan\n",
    "Portscan_df_y, Portscan_drop_df = copyLabelDropColumns(Friday_Portscan)\n",
    "#print(Portscan_df_y[:5])\n",
    "print(Portscan_drop_df.shape)\n",
    "\n",
    "#Friday DDOS\n",
    "DDOS_df_y, DDOS_drop_df = copyLabelDropColumns(Friday_DDOS)\n",
    "#print(DDOS_df_y[:5])\n",
    "print(DDOS_drop_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa479b5",
   "metadata": {},
   "source": [
    "#### What columns are left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92a8b4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets',\n",
      "       'Total Length of Fwd Packets', 'Total Length of Bwd Packets',\n",
      "       'Fwd Packet Length Max', 'Fwd Packet Length Min',\n",
      "       'Fwd Packet Length Mean', 'Fwd Packet Length Std',\n",
      "       'Bwd Packet Length Max', 'Bwd Packet Length Min',\n",
      "       'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s',\n",
      "       'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max',\n",
      "       'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std',\n",
      "       'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean',\n",
      "       'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd URG Flags',\n",
      "       'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s',\n",
      "       'Bwd Packets/s', 'Min Packet Length', 'Max Packet Length',\n",
      "       'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance',\n",
      "       'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count',\n",
      "       'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count',\n",
      "       'Down/Up Ratio', 'Average Packet Size', 'Avg Fwd Segment Size',\n",
      "       'Avg Bwd Segment Size', 'Subflow Fwd Bytes', 'Subflow Bwd Bytes',\n",
      "       'Init_Win_bytes_forward', 'Init_Win_bytes_backward', 'act_data_pkt_fwd',\n",
      "       'min_seg_size_forward', 'Active Mean', 'Active Std', 'Active Max',\n",
      "       'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(DDOS_drop_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d6fc78",
   "metadata": {},
   "source": [
    "#### Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fc0d65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeLabels(df):\n",
    "    df['Label_encoding'] = df['Label'].apply(lambda x: 0 if x == 'BENIGN' else 1)\n",
    "    df = df.drop(['Label'], axis=1)\n",
    "    return df\n",
    "\n",
    "Mon_df_y = encodeLabels(Mon_df_y)\n",
    "#Make into series\n",
    "Mon_df_y = Mon_df_y['Label_encoding'] \n",
    "#print(Mon_df_y[:5])\n",
    "\n",
    "BruteForce_df_y = encodeLabels(BruteForce_df_y)\n",
    "#Make into series\n",
    "BruteForce_df_y = BruteForce_df_y['Label_encoding'] \n",
    "#print(BruteForce_df_y[:5])\n",
    "\n",
    "DOS_df_y = encodeLabels(DOS_df_y)\n",
    "#Make into series\n",
    "DOS_df_y = DOS_df_y['Label_encoding'] \n",
    "#print(DOS_df_y[:5])\n",
    "\n",
    "WebAttack_df_y = encodeLabels(WebAttack_df_y)\n",
    "#Make into series\n",
    "WebAttack_df_y = WebAttack_df_y['Label_encoding']\n",
    "#print(WebAttack_df_y[:5])\n",
    "\n",
    "Infiltration_df_y = encodeLabels(Infiltration_df_y)\n",
    "#Make into series\n",
    "Infiltration_df_y = Infiltration_df_y['Label_encoding']\n",
    "#print(Infiltration_df_y[:5])\n",
    "\n",
    "Botnet_df_y = encodeLabels(Botnet_df_y)\n",
    "#Make into series\n",
    "Botnet_df_y = Botnet_df_y['Label_encoding']\n",
    "#print(Botnet_df_y[:5])\n",
    "\n",
    "Portscan_df_y = encodeLabels(Portscan_df_y)\n",
    "#Make into series\n",
    "Portscan_df_y = Portscan_df_y['Label_encoding']\n",
    "#print(Portscan_df_y[:5])\n",
    "\n",
    "DDOS_df_y = encodeLabels(DDOS_df_y)\n",
    "#Make into series\n",
    "DDOS_df_y = DDOS_df_y['Label_encoding']\n",
    "#print(DDOS_df_y[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4ba544",
   "metadata": {},
   "source": [
    "#### Check that correct labels are maintained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5268e0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Monday: ', '\\n', Mon_df_y['Label_encoding'].value_counts())\n",
    "#print('BruteForce:', '\\n',  BruteForce_df_y['Label_encoding'].value_counts())\n",
    "#print('DOS: ', '\\n', DOS_df_y['Label_encoding'].value_counts())\n",
    "#print('WebAttack: ', '\\n', WebAttack_df_y['Label_encoding'].value_counts())\n",
    "#print('Infiltration: ', '\\n', Infiltration_df_y['Label_encoding'].value_counts())\n",
    "#print('Botnet: ', '\\n', Botnet_df_y['Label_encoding'].value_counts())\n",
    "#print('Portscan: ', '\\n', Portscan_df_y['Label_encoding'].value_counts())\n",
    "#print('DDOS: ', '\\n', DDOS_df_y['Label_encoding'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859f57ed",
   "metadata": {},
   "source": [
    "#### Train test split all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b9a4d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monday train, test split\n",
    "X_Mon_train, X_Mon_test, Y_Mon_train, Y_Mon_test = train_test_split(\n",
    "    Mon_drop_df, Mon_df_y, \n",
    "    test_size=.2, \n",
    "    stratify=Mon_df_y, \n",
    "    random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ceeddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BruteForce train, test split\n",
    "X_BruteForce_train, X_BruteForce_test, Y_BruteForce_train, Y_BruteForce_test = train_test_split(\n",
    "    BruteForce_drop_df, BruteForce_df_y, \n",
    "    test_size=.2, \n",
    "    stratify=BruteForce_df_y, \n",
    "    random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bef1285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOS train, test split\n",
    "X_DOS_train, X_DOS_test, Y_DOS_train, Y_DOS_test = train_test_split(\n",
    "    DOS_drop_df, DOS_df_y, \n",
    "    test_size=.2, \n",
    "    stratify=DOS_df_y, \n",
    "    random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86fc48d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WebAttack train, test split\n",
    "X_WebAttack_train, X_WebAttack_test, Y_WebAttack_train, Y_WebAttack_test = train_test_split(\n",
    "    WebAttack_drop_df, WebAttack_df_y, \n",
    "    test_size=.2, \n",
    "    stratify=WebAttack_df_y, \n",
    "    random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4872d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Infiltration train, test split\n",
    "X_Infiltration_train, X_Infiltration_test, Y_Infiltration_train, Y_Infiltration_test = train_test_split(\n",
    "    Infiltration_drop_df, Infiltration_df_y, \n",
    "    test_size=.2, \n",
    "    stratify=Infiltration_df_y, \n",
    "    random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9edf6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Botnet train, test split\n",
    "X_Botnet_train, X_Botnet_test, Y_Botnet_train, Y_Botnet_test = train_test_split(\n",
    "    Botnet_drop_df, Botnet_df_y, \n",
    "    test_size=.2, \n",
    "    stratify=Botnet_df_y, \n",
    "    random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26f12d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Portscan train, test split\n",
    "X_Portscan_train, X_Portscan_test, Y_Portscan_train, Y_Portscan_test = train_test_split(\n",
    "    Portscan_drop_df, Portscan_df_y, \n",
    "    test_size=.2, \n",
    "    stratify=Portscan_df_y, \n",
    "    random_state=28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38f0a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Portscan train, test split\n",
    "X_DDOS_train, X_DDOS_test, Y_DDOS_train, Y_DDOS_test = train_test_split(\n",
    "    DDOS_drop_df, DDOS_df_y, \n",
    "    test_size=.2, \n",
    "    stratify=DDOS_df_y, \n",
    "    random_state=28)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a648745",
   "metadata": {},
   "source": [
    "#### Add Monday to all attack days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf112ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addMonday(x_train, x_test, y_train, y_test):\n",
    "    concat_x_train = pd.concat([X_Mon_train, x_train], ignore_index=True)\n",
    "    concat_x_test = pd.concat([X_Mon_test, x_test], ignore_index=True)\n",
    "    concat_y_train = pd.concat([Y_Mon_train, y_train], ignore_index=True)\n",
    "    concat_y_test = pd.concat([Y_Mon_test, y_test], ignore_index=True)\n",
    "    return concat_x_train, concat_x_test, concat_y_train, concat_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91fa2371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat BruteForce\n",
    "BruteForceMon_x_train, BruteForceMon_x_test, BruteForceMon_y_train, BruteForceMon_y_test = addMonday(X_BruteForce_train, X_BruteForce_test, Y_BruteForce_train, Y_BruteForce_test)\n",
    "\n",
    "#Concat DOS\n",
    "DOSMon_x_train, DOSMon_x_test, DOSMon_y_train, DOSMon_y_test = addMonday(X_DOS_train, X_DOS_test, Y_DOS_train, Y_DOS_test)\n",
    "\n",
    "#Concat WebAttack\n",
    "WebAttackMon_x_train, WebAttackMon_x_test, WebAttackMon_y_train, WebAttackMon_y_test = addMonday(X_WebAttack_train, X_WebAttack_test, Y_WebAttack_train, Y_WebAttack_test)\n",
    "\n",
    "#Concat Infiltration\n",
    "InfiltrationMon_x_train, InfiltrationMon_x_test, InfiltrationMon_y_train, InfiltrationMon_y_test = addMonday(X_Infiltration_train, X_Infiltration_test, Y_Infiltration_train, Y_Infiltration_test)\n",
    "\n",
    "#Concat Botnet\n",
    "BotnetMon_x_train, BotnetMon_x_test, BotnetMon_y_train, BotnetMon_y_test = addMonday(X_Botnet_train, X_Botnet_test, Y_Botnet_train, Y_Botnet_test)\n",
    "\n",
    "#Concat Portscan\n",
    "PortscanMon_x_train, PortscanMon_x_test, PortscanMon_y_train, PortscanMon_y_test = addMonday(X_Portscan_train, X_Portscan_test, Y_Portscan_train, Y_Portscan_test)\n",
    "\n",
    "#Concat DDOS\n",
    "DDOSMon_x_train, DDOSMon_x_test, DDOSMon_y_train, DDOSMon_y_test = addMonday(X_DDOS_train, X_DDOS_test, Y_DDOS_train, Y_DDOS_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee109f8f",
   "metadata": {},
   "source": [
    "#### Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b63f6ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleFeatures(train, test):\n",
    "    # Replace infinities with NaN\n",
    "    train = train.replace([np.inf, -np.inf], np.nan)\n",
    "    test  = test.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # Handle NaNs by filling with median of column\n",
    "    train_medians = train.median()\n",
    "    train = train.fillna(train_medians)\n",
    "    test  = test.fillna(train_medians)\n",
    "\n",
    "    #Declare scaler, fit on training\n",
    "    scaler = MinMaxScaler().fit(train)\n",
    "\n",
    "    #Transform train, test\n",
    "    train_scaled = pd.DataFrame(scaler.transform(train), columns=train.columns)\n",
    "    test_scaled  = pd.DataFrame(scaler.transform(test), columns=test.columns)\n",
    "\n",
    "    return train_scaled, test_scaled\n",
    "\n",
    "#Scale BruteForce\n",
    "BruteForceMon_x_train, BruteForceMon_x_test = scaleFeatures(BruteForceMon_x_train, BruteForceMon_x_test)\n",
    "#Scale DOS\n",
    "DOSMon_x_train, DOSMon_x_test = scaleFeatures(DOSMon_x_train, DOSMon_x_test)\n",
    "#Scale WebAttack\n",
    "WebAttackMon_x_train, WebAttackMon_x_test = scaleFeatures(WebAttackMon_x_train, WebAttackMon_x_test)\n",
    "#Scale Infiltration\n",
    "InfiltrationMon_x_train, InfiltrationMon_x_test = scaleFeatures(InfiltrationMon_x_train, InfiltrationMon_x_test)\n",
    "#Scale Botnet\n",
    "BotnetMon_x_train, BotnetMon_x_test = scaleFeatures(BotnetMon_x_train, BotnetMon_x_test)\n",
    "#Scale Portscan\n",
    "PortscanMon_x_train, PortscanMon_x_test = scaleFeatures(PortscanMon_x_train, PortscanMon_x_test)\n",
    "#Scale DDOS\n",
    "DDOSMon_x_train, DDOSMon_x_test = scaleFeatures(DDOSMon_x_train, DDOSMon_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65c7e18",
   "metadata": {},
   "source": [
    "#### The Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07ab6304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "logistic = LogisticRegression(max_iter=100)\n",
    "\n",
    "scoring = {'AUC': 'roc_auc', 'Accuracy': 'accuracy', 'Average Precision': 'average_precision', 'F1': 'f1'}\n",
    "\n",
    "param_grid_logistic = [\n",
    "    # L2 (liblinear or lbfgs)\n",
    "    {'penalty': ['l2'],\n",
    "     'C': [0.01, 0.1, 1, 10],\n",
    "     'solver': ['liblinear', 'lbfgs']},\n",
    "\n",
    "    # L1 (liblinear only)\n",
    "    {'penalty': ['l1'],\n",
    "     'C': [0.01, 0.1, 1, 10],\n",
    "     'solver': ['liblinear']},\n",
    "\n",
    "    # No penalty (lbfgs)\n",
    "    {'penalty': ['none'],\n",
    "     'solver': ['lbfgs']}\n",
    "]\n",
    "\n",
    "# Setting refit='AUC', refits an estimator on the whole dataset with the\n",
    "# parameter setting that has the best cross-validated AUC score.\n",
    "# That estimator is made available at ``gs.best_estimator_`` along with\n",
    "# parameters like ``gs.best_score_``, ``gs.best_params_`` and\n",
    "# ``gs.best_index_``\n",
    "grid_search_logistic = GridSearchCV(\n",
    "    logistic, \n",
    "    param_grid=param_grid_logistic,\n",
    "    refit='AUC',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring=scoring\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf6de526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [1, 3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'leaf_size': [5, 10, 15, 20, 25, 30, 35, 40]\n",
    "}\n",
    "grid_search_knn = GridSearchCV(\n",
    "    knn,\n",
    "    param_grid=param_grid_knn,\n",
    "    refit='AUC',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring=scoring\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "274217c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classifier\n",
    "random = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 500],       \n",
    "    'max_depth': [None, 10, 20, 30],       \n",
    "    'min_samples_split': [2, 5, 10],        \n",
    "    'min_samples_leaf': [1, 2, 4],          \n",
    "    'max_features': ['sqrt', 'log2', None]  \n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    random,\n",
    "    param_grid=param_grid_rf,\n",
    "    refit='AUC',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring=scoring   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe1e0234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP Classifier\n",
    "mlpclassifier = MLPClassifier(max_iter=100)\n",
    "\n",
    "param_grid_mlp = {\n",
    "   'hidden_layer_sizes': [(32,), (64,), (128,),(64, 32), (128, 64)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],  \n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "}\n",
    "\n",
    "grid_search_mlp = GridSearchCV(\n",
    "   mlpclassifier,\n",
    "   param_grid=param_grid_mlp,\n",
    "   refit='AUC',\n",
    "   cv=5,\n",
    "   n_jobs=-1,\n",
    "   scoring=scoring\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2319d417",
   "metadata": {},
   "source": [
    "#### Brute Force Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab4e10d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Logistic Regression\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mgrid_search_logistic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBruteForceMon_x_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBruteForceMon_y_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m BF_logistic_bestestimator \u001b[38;5;241m=\u001b[39m grid_search_logistic\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m      4\u001b[0m BF_logistic_bestparams \u001b[38;5;241m=\u001b[39m grid_search_logistic\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/joblib/parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/joblib/parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cs135_env/lib/python3.10/site-packages/joblib/parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[1;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[1;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[1;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[1;32m   1799\u001b[0m     ):\n\u001b[0;32m-> 1800\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[1;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[1;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "grid_search_logistic.fit(BruteForceMon_x_train, BruteForceMon_y_train)\n",
    "BF_logistic_bestestimator = grid_search_logistic.best_estimator_\n",
    "BF_logistic_bestparams = grid_search_logistic.best_params_\n",
    "BF_logistic_bestscore = grid_search_logistic.best_score_\n",
    "print('Brute Force \\n')\n",
    "print('Logistic Regression \\n')\n",
    "print(\"Best parameters:\", BF_logistic_bestparams)\n",
    "print(\"Best cross-val score: {:.2f}%\".format(BF_logistic_bestscore * 100))\n",
    "print('Test score:')\n",
    "\n",
    "#KNN\n",
    "grid_search_knn.fit(BruteForceMon_x_train, BruteForceMon_y_train)\n",
    "BF_knn_bestestimator = grid_search_knn.best_estimator_\n",
    "BF_knn_bestparams = grid_search_knn.best_params_\n",
    "BF_knn_bestscore = grid_search_knn.best_score_\n",
    "print('KNN \\n')\n",
    "print(\"Best parameters for knn:\", BF_knn_bestparams)\n",
    "print(\"Best score for knn: {:.2f}%\".format(BF_knn_bestscore * 100))\n",
    "print('Test score:')\n",
    "\n",
    "#Random Forest Classifier\n",
    "grid_search_rf.fit(BruteForceMon_x_train, BruteForceMon_y_train)\n",
    "BF_rf_bestestimator = grid_search_rf.best_estimator_\n",
    "BF_rf_bestparams = grid_search_rf.best_params_\n",
    "BF_rf_bestscore = grid_search_rf.best_score_\n",
    "print('Random Forest \\n')\n",
    "print(\"Best parameters for random forest:\", BF_rf_bestparams)\n",
    "print(\"Best score for random forest: {:.2f}%\".format(BF_rf_bestscore * 100))\n",
    "print('Test score:')\n",
    "\n",
    "#MLP Classifier\n",
    "grid_search_mlp.fit(BruteForceMon_x_train, BruteForceMon_y_train)\n",
    "BF_mlp_bestestimator = grid_search_mlp.best_estimator_\n",
    "BF_mlp_bestparams = grid_search_mlp.best_params_\n",
    "BF_mlp_bestscore = grid_search_mlp.best_score_\n",
    "print('Multi-Layer Perceptron \\n')\n",
    "print(\"Best parameters for random forest:\", BF_mlp_bestparams)\n",
    "print(\"Best score for random forest: {:.2f}%\".format(BF_mlp_bestscore * 100))\n",
    "print('Test score:')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dc3abb",
   "metadata": {},
   "source": [
    "#### DOS Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1821b4",
   "metadata": {},
   "source": [
    "#### WebAttack Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8833cc",
   "metadata": {},
   "source": [
    "#### Infiltration Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99bc60e",
   "metadata": {},
   "source": [
    "#### Botnet Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbf7455",
   "metadata": {},
   "source": [
    "#### Portscan Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5c1e97",
   "metadata": {},
   "source": [
    "#### DDOS Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs135_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
